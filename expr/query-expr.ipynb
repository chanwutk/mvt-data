{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705077e8-d808-4ee9-939e-04dc97d018bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783a462-3c56-49a6-afce-6826c7f90f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c302b49b-37f7-4d6b-9d4f-324ee3913dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = df.with_columns(trajectory_id=pl.Series(values=[*range(len(df))]))#.filter(pl.col('trajectory_id') == 763)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae33f2-6ca2-45ac-b6a3-4eb24034864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6085d-1cdf-446c-b7af-04a00acf91ca",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92250fef-5cd4-483a-9203-d11b7893dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "df_flatten = (df_mod.select(\n",
    "        pl.col('trajectory_id'),\n",
    "        pl.col('timestamp'),\n",
    "        pl.col('downstream_av_id'),\n",
    "        pl.col('distance_to_downstream_av_meters'),\n",
    "    )\n",
    "    .filter(pl.col('downstream_av_id').list.len() != 0)\n",
    "    .with_columns(\n",
    "        timestamp_int=pl.col('timestamp')\n",
    "            .map_elements(lambda ts: [int(ts[0] * 100 + 0.5) + int((t - ts[0]) * 100 + 0.5) for t in ts],\n",
    "                                                       return_dtype=list[int]),\n",
    "        rank=pl.col('timestamp')\n",
    "            .map_elements(lambda ts: list(range(len(ts))),\n",
    "                                              return_dtype=list[int]),\n",
    "    )\n",
    "    # int\n",
    "    .explode(\n",
    "        'timestamp',\n",
    "        'timestamp_int',\n",
    "        'downstream_av_id',\n",
    "        'distance_to_downstream_av_meters',\n",
    "        'rank',\n",
    "    )\n",
    "    .drop_nulls('downstream_av_id')\n",
    ")\n",
    "df_flatten.sort('rank').filter((1040 < pl.col.rank) & (pl.col.rank < 1050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cf85b-e1f1-4e14-b393-bdd4276ecffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def interpolate(arr):\n",
    "    last = arr[-1]\n",
    "    arr = np.array(arr)\n",
    "    prv = arr[:-1]\n",
    "    nxt = arr[1:]\n",
    "    dff = nxt - prv\n",
    "    dff25 = prv + dff * .25\n",
    "    dff50 = prv + dff * .50\n",
    "    dff75 = prv + dff * .75\n",
    "    return list(np.stack((prv, dff25, dff50, dff75), axis=-1).flatten()) + [last]\n",
    "\n",
    "def fillnone(arr, nones):\n",
    "    chunks = []\n",
    "    for idx, prv, nxt in reversed(nones):\n",
    "        dist = nxt - prv\n",
    "        assert dist % 4 == 0, (nxt, prv)\n",
    "        chunk = arr[idx+1:]\n",
    "        arr = arr[:idx+1]\n",
    "        chunks.append(chunk)\n",
    "    # chunks.append(arr)\n",
    "    chunks.reverse()\n",
    "\n",
    "    return list(itertools.chain(*itertools.chain([arr], *((([float('nan')] * ((nxt - prv) // 4 - 1)), chunk) for (_, prv, nxt), chunk in zip(nones, chunks)))))\n",
    "def fillnone2(arr, nones):\n",
    "    chunks = []\n",
    "    for idx, prv, nxt in reversed(nones):\n",
    "        dist = nxt - prv\n",
    "        assert dist % 4 == 0, (nxt, prv)\n",
    "        chunk = arr[idx+1:]\n",
    "        arr = arr[:idx+1]\n",
    "        chunks.append(chunk)\n",
    "    # chunks.append(arr)\n",
    "    chunks.reverse()\n",
    "\n",
    "    return list(itertools.chain(*itertools.chain([arr], *((([None] * ((nxt - prv) // 4 - 1)), chunk) for (_, prv, nxt), chunk in zip(nones, chunks)))))\n",
    "    \n",
    "\n",
    "df_flatten_interpolate = (df_flatten\n",
    "    .group_by('trajectory_id', 'downstream_av_id')\n",
    "    .all()\n",
    "    .with_columns(\n",
    "        nones=pl.col('timestamp_int').map_elements(lambda ts: [(idx, prv, nxt) for idx, (prv, nxt) in enumerate(zip(ts[:-1], ts[1:])) if nxt - prv != 4], return_dtype=list[tuple[int, int, int]])\n",
    "    )\n",
    "    # .filter(c.nones.list.len() != 0)\n",
    "    .with_columns(\n",
    "        timestamp=pl.struct('nones', 'timestamp').map_elements(lambda r: fillnone(r['timestamp'], r['nones']), return_dtype=list[float]),\n",
    "        distance_to_downstream_av_meters=pl.struct('nones', 'distance_to_downstream_av_meters').map_elements(lambda r: fillnone(r['distance_to_downstream_av_meters'], r['nones']), return_dtype=list[float]),\n",
    "        timestamp_int=pl.struct('nones', 'timestamp_int').map_elements(lambda r: fillnone2(r['timestamp_int'], r['nones']), return_dtype=list[int]),\n",
    "        rank=pl.struct('nones', 'rank').map_elements(lambda r: fillnone2(r['rank'], r['nones']), return_dtype=list[int]),\n",
    "    )\n",
    "    .with_columns(\n",
    "        timestamp=pl.col('timestamp').map_elements(interpolate, return_dtype=list[float]),\n",
    "        distance_to_downstream_av_meters=pl.col('distance_to_downstream_av_meters').map_elements(interpolate, return_dtype=list[float]),\n",
    "        timestamp_int=pl.col('timestamp_int').map_elements(lambda ts: list(range(ts[0], ts[-1] + 1)), return_dtype=list[int]),\n",
    "        rank=pl.col('rank').map_elements(lambda r: range(r[0] * 4, r[-1] * 4 + 1), return_dtype=list[int]),\n",
    "    )\n",
    "    # .with_columns(\n",
    "    #     timestamp_len=pl.col('timestamp').list.len(),\n",
    "    #     distance_to_downstream_av_meters_len=pl.col('distance_to_downstream_av_meters').list.len(),\n",
    "    #     # timestamp_int=pl.col('timestamp_int').map_elements(lambda ts: len(list(range(ts[0], ts[-1] + 1))), return_dtype=int),\n",
    "    #     # rank=pl.col('rank').map_elements(lambda r: len(range(r[0], r[0] + (len(r) - 1) * 4 + 1)), return_dtype=int),\n",
    "    # )\n",
    "    .drop('nones')\n",
    "    .explode(\n",
    "        'timestamp',\n",
    "        'distance_to_downstream_av_meters',\n",
    "        'timestamp_int',\n",
    "        'rank',\n",
    "    )\n",
    "    # .drop_nans('timestamp')\n",
    "    .filter(\n",
    "        ~pl.col('timestamp').is_nan()\n",
    "    )\n",
    "    # .filter(\n",
    "    #     (pl.col('timestamp').list.len() != pl.col('rank').list.len()) |\n",
    "    #     (pl.col('timestamp').list.len() != pl.col('timestamp_int').list.len()) |\n",
    "    #     (pl.col('timestamp').list.len() != pl.col('distance_to_downstream_av_meters').list.len())\n",
    "    # )\n",
    ")#['timestamp_int'][0]\n",
    "# with pl.Config(tbl_rows=30):\n",
    "#     print(df_flatten_interpolate.sort('rank', 'downstream_av_id').filter((4155 < pl.col('rank'))&(pl.col('rank')<4170)))\n",
    "\n",
    "en1 = time.time() - st\n",
    "df_flatten_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3478b2-b91b-48d2-8ef7-fcdcce29528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_1 = (df_flatten_interpolate\n",
    "    .group_by('downstream_av_id', 'timestamp_int')\n",
    "    .all()\n",
    "    .with_columns(\n",
    "        min_idx=pl.col('distance_to_downstream_av_meters').list.arg_min()\n",
    "    )\n",
    "    .with_columns(\n",
    "        timestamp=pl.col('timestamp').list.get(pl.col('min_idx')),\n",
    "        trajectory_id=pl.col('trajectory_id').list.get(pl.col('min_idx')),\n",
    "        distance_to_downstream_av_meters=pl.col('distance_to_downstream_av_meters').list.get(pl.col('min_idx')),\n",
    "        rank=pl.col('rank').list.get(pl.col('min_idx')),\n",
    "    )\n",
    "    .drop('min_idx', 'timestamp_int')\n",
    "    .filter(pl.col('rank') % 4 == 0)\n",
    "    .sort('timestamp')\n",
    "    .group_by('downstream_av_id')\n",
    "    .all()\n",
    ")\n",
    "df_out_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02202dde-8bc6-4a26-a98f-daab71579f50",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffb1ab-59ba-4711-96a1-cddfffdf470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS = 'downstream'\n",
    "POS = 'upstream'\n",
    "\n",
    "def new_av(aid):\n",
    "    \"\"\"\n",
    "    Given a list of av_ids, return a list of indices of when av_id changes.\n",
    "    \"\"\"\n",
    "    aid = np.array([a if a is not None else -1 for a in aid], dtype=int)\n",
    "    return list(np.argwhere(aid[:-1] != aid[1:])[:, 0] + 1)\n",
    "\n",
    "\n",
    "df_split_av_ = (df\n",
    "    .select(\n",
    "        pl.col('trajectory_id'),\n",
    "        pl.col('timestamp'),\n",
    "        pl.col(f'{POS}_av_id'),\n",
    "        pl.col(f'distance_to_{POS}_av_meters'),\n",
    "    )\n",
    "    .rename({'trajectory_id': 'tid', f'{POS}_av_id': 'avid', f'distance_to_{POS}_av_meters': 'dist'})\n",
    "    # Remove all the trajectories without any av id.\n",
    "    .filter(pl.col('avid').list.drop_nulls().list.len() != 0)\n",
    "    .with_columns(\n",
    "        # Since the timestamps for each trajectories do not align, we snap the timestamp of all the trajectories to the nearest millisecond.\n",
    "        timestamp_int=pl.col('timestamp')\n",
    "            .map_elements(lambda ts: [int(ts[0] * 100 + 0.5) + int((t - ts[0]) * 100 + 0.5) for t in ts],\n",
    "                          return_dtype=list[int]),\n",
    "        # A list of indices of a trajectory points. Will be used to reference each point of the trajectory.\n",
    "        trajectory_point_idx=pl.col('timestamp')\n",
    "            .map_elements(lambda ts: list(range(len(ts))),\n",
    "                          return_dtype=list[int]),\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Derive when a trajectory changes its up/down-stream AV.\n",
    "        new_av=pl.col('avid')\n",
    "            .map_elements(new_av, return_dtype=list[int])\n",
    "    )\n",
    "    .with_columns(\n",
    "        # Split timestamps based on the AV the trajectory follow / lead.\n",
    "        timestamp=pl.struct('timestamp', 'new_av')\n",
    "            .map_elements(lambda x: [list(l) for l in np.split(x['timestamp'], x['new_av'])],\n",
    "                          return_dtype=list[list[float]]),\n",
    "        # Split avid based on the AV the trajectory follow / lead.\n",
    "        # Take the first AV id because all the ids in the splitted array are the same (because we split by AV id)\n",
    "        avid=pl.struct('avid', 'new_av')\n",
    "            .map_elements(lambda x: [l[0] for l in np.split(x['avid'], x['new_av'])],\n",
    "                          return_dtype=list[int]),\n",
    "        # Split dist based on the AV the trajectory follow / lead.\n",
    "        dist=pl.struct('dist', 'new_av')\n",
    "            .map_elements(lambda x: [list(l) for l in np.split(x['dist'], x['new_av'])],\n",
    "                          return_dtype=list[list[float]]),\n",
    "        # Split timestamp_int based on the AV the trajectory follow / lead.\n",
    "        timestamp_int=pl.struct('timestamp_int', 'new_av')\n",
    "            .map_elements(lambda x: [list(l) for l in np.split(x['timestamp_int'], x['new_av'])],\n",
    "                          return_dtype=list[list[int]]),\n",
    "        # Split trajectory_point_idx based on the AV the trajectory follow / lead.\n",
    "        trajectory_point_idx=pl.struct('trajectory_point_idx', 'new_av')\n",
    "            .map_elements(lambda x: [list(l) for l in np.split(x['trajectory_point_idx'], x['new_av'])],\n",
    "                          return_dtype=list[list[int]]),\n",
    "    )\n",
    ")\n",
    "df_split_av_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d57f5-f8bc-477f-8db9-328c9af405d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_av = (df_split_av_\n",
    "    .drop('new_av')\n",
    "    .explode(\n",
    "        # list[list[timestamp]] per row -> list[timestamp] per row\n",
    "        'timestamp',\n",
    "        # list[list[timestamp_int]] per row -> list[timestamp_int] per row\n",
    "        'timestamp_int',\n",
    "        # list[avid] per row -> avid per row\n",
    "        'avid',\n",
    "        # list[list[dist]] per row -> list[dist] per row\n",
    "        'dist',\n",
    "        # list[list[trajectory_point_idx]] per row -> list[trajectory_point_idx] per row\n",
    "        'trajectory_point_idx',\n",
    "    )\n",
    "    .filter(~pl.col('avid').is_null())\n",
    ")\n",
    "df_split_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43735922-69eb-442b-ae3f-bbb8b74e14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def interpolate(arr):\n",
    "    last = arr[-1]\n",
    "    arr = np.array(arr)\n",
    "    prv = arr[:-1]\n",
    "    nxt = arr[1:]\n",
    "    dff = nxt - prv\n",
    "    dff25 = prv + dff * .25\n",
    "    dff50 = prv + dff * .50\n",
    "    dff75 = prv + dff * .75\n",
    "    return list(np.stack((prv, dff25, dff50, dff75), axis=-1).flatten()) + [last]\n",
    "\n",
    "\n",
    "df_interpolate_ = (df_split_av\n",
    "    .with_columns(\n",
    "        # Points of a trajectories are captured roughly every 4 millisecond and 2 trajectories might not align, so we interpolate trajectories points to every 1 millisecond.\n",
    "        timestamp_int=pl.col('timestamp_int').map_elements(lambda ts: list(range(ts[0], ts[-1] + 1)), return_dtype=list[int]),\n",
    "        # Interpolate timestamp\n",
    "        timestamp=pl.col('timestamp').map_elements(interpolate, return_dtype=list[float]),\n",
    "        # Interpolate dist\n",
    "        dist=pl.col('dist').map_elements(interpolate, return_dtype=list[float]),\n",
    "        # Interpolate trajectory_point_idx\n",
    "        trajectory_point_idx_interp=pl.col('trajectory_point_idx').map_elements(lambda r: range(r[0] * 4, r[-1] * 4 + 1), return_dtype=list[int]),\n",
    "        # avid=pl.col('avid').list.first(),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_interpolate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9775d3-2bdd-4c66-92c3-6d0ad07e8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpolate = (df_interpolate_\n",
    "    # Drop the original trajectory_point_idx it has different lenght than other columns (cannot explode)\n",
    "    .drop('trajectory_point_idx')\n",
    "    .explode(\n",
    "        # Flatten all trajectories points\n",
    "        'timestamp',\n",
    "        'dist',\n",
    "        'timestamp_int',\n",
    "        'trajectory_point_idx_interp',\n",
    "    )\n",
    ")\n",
    "df_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b75f1-d8a2-42c3-bb84-c793927ad654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interpolate_grouped = (df_interpolate\n",
    "    # For every AV id and every timestamp (snapped to the nearest millissecond -> every millisecond)\n",
    "    .group_by('avid', 'timestamp_int')\n",
    "    # Roll up ungrouped columns into lists\n",
    "    .all()\n",
    "    .with_columns(\n",
    "        # Find the index of the nearest vehicle\n",
    "        nearest_idx=pl.col('dist').list.arg_min()\n",
    "            if POS == 'downstream'\n",
    "            else pl.col('dist').list.arg_max()\n",
    "    )\n",
    ")\n",
    "df_interpolate_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504f6d9-4537-4209-a4a9-e18ac90dd42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nearest = (df_interpolate_grouped\n",
    "    .with_columns(\n",
    "        # Choose the vehicle from the index\n",
    "        timestamp=pl.col('timestamp').list.get(pl.col('nearest_idx')),\n",
    "        trajectory_id=pl.col('tid').list.get(pl.col('nearest_idx')),\n",
    "        dist=pl.col('dist').list.get(pl.col('nearest_idx')),\n",
    "        trajectory_point_idx_interp=pl.col('trajectory_point_idx_interp').list.get(pl.col('nearest_idx')),\n",
    "    )\n",
    "    .drop('nearest_idx', 'tid')\n",
    "    # Only include the non-interpolated trajectory points\n",
    "    .filter(pl.col('trajectory_point_idx_interp') % 4 == 0)\n",
    "    .sort('timestamp')\n",
    "    # (trajectory_id, trajectory_point_idx) can now be used to reference the trajectory points in the original dataframe.\n",
    "    .with_columns(trajectory_point_idx=pl.col('trajectory_point_idx_interp') // 4)\n",
    ")\n",
    "df_nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67326192-a013-414a-9358-1844f7b0857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_nearest\n",
    "    .group_by('avid')\n",
    "    # Roll up ungrouped columns into lists\n",
    "    .all()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99045293-c3a5-4411-a95e-33415cc6f72b",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99130f3d-8109-4b33-ba28-87ba80480474",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_flatten_interpolate.rename({'trajectory_id': 'tid', 'downstream_av_id': 'avid', 'distance_to_downstream_av_meters': 'dist', 'rank': 'loc_idx'}).select('tid', 'timestamp_int', 'avid', 'dist', 'loc_idx')\n",
    "a.sort('tid', 'timestamp_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf09ed-49ce-4e41-a67e-1b57b84bc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df_interpolate.select('tid', 'timestamp_int', 'avid', 'dist', 'loc_idx')\n",
    "b.sort('tid', 'timestamp_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071fdd84-1bfd-49d9-9b90-323072ab2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.join(a, on=['tid', 'timestamp_int', 'loc_idx'], how='anti').sort('tid', 'loc_idx', 'timestamp_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e2e13-68ea-419d-b72e-e947e39eb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.join(b, on=['tid', 'timestamp_int', 'avid', 'loc_idx'], how='anti').sort('tid', 'loc_idx', 'timestamp_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b0d509-24f1-4ae0-8f58-255b5a7e7a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_1.rename({'downstream_av_id': 'avid', 'distance_to_downstream_av_meters': 'dist', 'rank': 'loc_idx'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b815a19-dbc1-4746-9126-79036351f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081936a0-87c8-407d-9785-c82f7f5c9acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "join = df_out_1.rename({'downstream_av_id': 'avid', 'distance_to_downstream_av_meters': 'dist', 'rank': 'loc_idx'}).join(df_out_2, on='avid', how='anti')\n",
    "join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bcb102-1eca-4074-8284-e5c5868eb38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "join = df_out_2.join(df_out_1.rename({'downstream_av_id': 'avid', 'distance_to_downstream_av_meters': 'dist', 'rank': 'loc_idx'}), on='avid', how='anti')\n",
    "join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e9fdf-983a-408d-920a-e34d63e6f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "en1, en2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9931667-f707-43c2-83aa-7d9997e234ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
